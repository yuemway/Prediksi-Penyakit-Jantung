{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vhRVF-OmARoc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LOFjTc9UHO2U"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('../heart.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9rC964IMW1RE",
        "outputId": "e462a99e-b742-4143-bce0-c8e39f55bcc5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gvwyTt2gWK-i",
        "outputId": "146a597f-8d6e-4646-e42e-110ba0055d5e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6071</th>\n",
              "      <td>62</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>263</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>97</td>\n",
              "      <td>0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6072</th>\n",
              "      <td>58</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>100</td>\n",
              "      <td>248</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6073</th>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>138</td>\n",
              "      <td>271</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>182</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6074</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>130</td>\n",
              "      <td>283</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>103</td>\n",
              "      <td>1</td>\n",
              "      <td>1.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6075</th>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>150</td>\n",
              "      <td>243</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
              "6071   62    0   2       130   263    0        0       97      0      1.2   \n",
              "6072   58    0   3       100   248    0        2      122      0      1.0   \n",
              "6073   59    1   3       138   271    0        2      182      0      0.0   \n",
              "6074   56    1   3       130   283    1        2      103      1      1.6   \n",
              "6075   50    1   3       150   243    0        2      128      0      2.6   \n",
              "\n",
              "      slope  ca  thal  target  \n",
              "6071      1   1     2       1  \n",
              "6072      1   0     0       0  \n",
              "6073      0   0     0       0  \n",
              "6074      2   0     2       1  \n",
              "6075      1   0     2       1  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMYDjY9UP_DO",
        "outputId": "4a1173a2-0734-41a6-ccf5-7d9b776d3ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6076 entries, 0 to 6075\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       6076 non-null   int64  \n",
            " 1   sex       6076 non-null   int64  \n",
            " 2   cp        6076 non-null   int64  \n",
            " 3   trestbps  6076 non-null   int64  \n",
            " 4   chol      6076 non-null   int64  \n",
            " 5   fbs       6076 non-null   int64  \n",
            " 6   restecg   6076 non-null   int64  \n",
            " 7   thalach   6076 non-null   int64  \n",
            " 8   exang     6076 non-null   int64  \n",
            " 9   oldpeak   6076 non-null   float64\n",
            " 10  slope     6076 non-null   int64  \n",
            " 11  ca        6076 non-null   int64  \n",
            " 12  thal      6076 non-null   int64  \n",
            " 13  target    6076 non-null   int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 664.7 KB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MoB16uMs61Ox"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Pisahkan fitur dan target\n",
        "X = data.drop(columns=['target'])\n",
        "y = data['target']\n",
        "\n",
        "# Bagi data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Normalisasi\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40QEzz_o50dj",
        "outputId": "842d572e-f5ff-4a9c-cf36-4ab530a8a155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi Model: 0.73\n",
            "Laporan Klasifikasi:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.74      0.74       640\n",
            "           1       0.71      0.72      0.72       576\n",
            "\n",
            "    accuracy                           0.73      1216\n",
            "   macro avg       0.73      0.73      0.73      1216\n",
            "weighted avg       0.73      0.73      0.73      1216\n",
            "\n",
            "Prediksi untuk data baru: Sehat\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\UMMY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Buat model Naive Bayes\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluasi\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Akurasi Model: {accuracy:.2f}')\n",
        "print('Laporan Klasifikasi:\\n', report)\n",
        "\n",
        "# Prediksi data baru (contoh input)\n",
        "data_baru = np.array([[63, 1, 3, 145, 233, 1, 0, 150, 0, 2.3, 0, 0, 1]])  # Sesuaikan input\n",
        "\n",
        "# Normalisasi data baru\n",
        "data_baru = scaler.transform(data_baru)\n",
        "\n",
        "# Prediksi hasil data baru\n",
        "hasil_prediksi = model.predict(data_baru)\n",
        "print(f'Prediksi untuk data baru: {\"Penyakit Jantung\" if hasil_prediksi[0] == 1 else \"Sehat\"}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0BOzyKg67MQ",
        "outputId": "81a91f29-f81c-4805-abae-96accc7f7b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9104\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.93      0.92       640\n",
            "           1       0.91      0.89      0.90       576\n",
            "\n",
            "    accuracy                           0.91      1216\n",
            "   macro avg       0.91      0.91      0.91      1216\n",
            "weighted avg       0.91      0.91      0.91      1216\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Buat dan latih model SVM\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42, probability=True)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluasi\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPSd_e8A_R9Z",
        "outputId": "7a7f4c06-6658-44ed-853a-579b28eb4571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi rata-rata SVM: 0.6116\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "svm = SVC(C=1, kernel='rbf', gamma='scale')\n",
        "scores = cross_val_score(svm, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "print(f\"Akurasi rata-rata SVM: {scores.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IT46iOnF93HI",
        "outputId": "4f2a2fa7-ca9c-487c-d788-0c29929c6049"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Best Accuracy: 0.9487654320987653\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "svm = SVC()\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abi1o2Hx-5-O",
        "outputId": "c75c1c03-4aee-4f62-bfbe-537cef9705ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'C': 50, 'gamma': 'scale'}\n",
            "Best Accuracy: 0.9493827160493827\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "param_grid = {\n",
        "    'C': [10, 50, 100, 500, 1000],\n",
        "    'gamma': [0.1, 0.01, 0.001, 0.0001, 'scale', 'auto'],\n",
        "}\n",
        "\n",
        "svm = SVC()\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJJd-uQz7nsG",
        "outputId": "9b20d972-90c8-4df1-ffa8-4790a89d5b57"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\UMMY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.6354 - loss: 0.6348 - val_accuracy: 0.7490 - val_loss: 0.4858\n",
            "Epoch 2/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7344 - loss: 0.5002 - val_accuracy: 0.7757 - val_loss: 0.4443\n",
            "Epoch 3/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7882 - loss: 0.4334 - val_accuracy: 0.7860 - val_loss: 0.4260\n",
            "Epoch 4/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7896 - loss: 0.4346 - val_accuracy: 0.8066 - val_loss: 0.4083\n",
            "Epoch 5/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7914 - loss: 0.4371 - val_accuracy: 0.8045 - val_loss: 0.3964\n",
            "Epoch 6/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8213 - loss: 0.3983 - val_accuracy: 0.8158 - val_loss: 0.3891\n",
            "Epoch 7/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8226 - loss: 0.3870 - val_accuracy: 0.8344 - val_loss: 0.3772\n",
            "Epoch 8/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8294 - loss: 0.3797 - val_accuracy: 0.8323 - val_loss: 0.3656\n",
            "Epoch 9/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8215 - loss: 0.3720 - val_accuracy: 0.8405 - val_loss: 0.3572\n",
            "Epoch 10/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8413 - loss: 0.3550 - val_accuracy: 0.8519 - val_loss: 0.3524\n",
            "Epoch 11/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8285 - loss: 0.3681 - val_accuracy: 0.8560 - val_loss: 0.3416\n",
            "Epoch 12/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8378 - loss: 0.3410 - val_accuracy: 0.8519 - val_loss: 0.3400\n",
            "Epoch 13/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8567 - loss: 0.3360 - val_accuracy: 0.8663 - val_loss: 0.3261\n",
            "Epoch 14/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.8513 - loss: 0.3348 - val_accuracy: 0.8663 - val_loss: 0.3133\n",
            "Epoch 15/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8595 - loss: 0.3280 - val_accuracy: 0.8724 - val_loss: 0.3173\n",
            "Epoch 16/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8606 - loss: 0.3332 - val_accuracy: 0.8817 - val_loss: 0.2991\n",
            "Epoch 17/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8404 - loss: 0.3237 - val_accuracy: 0.8807 - val_loss: 0.3012\n",
            "Epoch 18/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8623 - loss: 0.3064 - val_accuracy: 0.8714 - val_loss: 0.2946\n",
            "Epoch 19/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 0.3013 - val_accuracy: 0.8807 - val_loss: 0.2882\n",
            "Epoch 20/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8649 - loss: 0.3199 - val_accuracy: 0.8889 - val_loss: 0.2764\n",
            "Epoch 21/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8749 - loss: 0.2946 - val_accuracy: 0.8909 - val_loss: 0.2689\n",
            "Epoch 22/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8693 - loss: 0.2894 - val_accuracy: 0.8971 - val_loss: 0.2661\n",
            "Epoch 23/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8751 - loss: 0.2823 - val_accuracy: 0.8951 - val_loss: 0.2669\n",
            "Epoch 24/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8716 - loss: 0.2760 - val_accuracy: 0.8981 - val_loss: 0.2700\n",
            "Epoch 25/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8721 - loss: 0.2902 - val_accuracy: 0.9064 - val_loss: 0.2572\n",
            "Epoch 26/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8755 - loss: 0.2783 - val_accuracy: 0.9012 - val_loss: 0.2518\n",
            "Epoch 27/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8723 - loss: 0.2717 - val_accuracy: 0.9095 - val_loss: 0.2487\n",
            "Epoch 28/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8783 - loss: 0.2897 - val_accuracy: 0.9074 - val_loss: 0.2479\n",
            "Epoch 29/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8756 - loss: 0.2817 - val_accuracy: 0.8899 - val_loss: 0.2542\n",
            "Epoch 30/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8799 - loss: 0.2676 - val_accuracy: 0.8992 - val_loss: 0.2502\n",
            "Epoch 31/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8878 - loss: 0.2567 - val_accuracy: 0.9043 - val_loss: 0.2473\n",
            "Epoch 32/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8949 - loss: 0.2452 - val_accuracy: 0.8940 - val_loss: 0.2391\n",
            "Epoch 33/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8970 - loss: 0.2383 - val_accuracy: 0.9012 - val_loss: 0.2369\n",
            "Epoch 34/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8869 - loss: 0.2596 - val_accuracy: 0.8971 - val_loss: 0.2373\n",
            "Epoch 35/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.2498 - val_accuracy: 0.9002 - val_loss: 0.2303\n",
            "Epoch 36/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8978 - loss: 0.2395 - val_accuracy: 0.9012 - val_loss: 0.2249\n",
            "Epoch 37/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8916 - loss: 0.2499 - val_accuracy: 0.9012 - val_loss: 0.2255\n",
            "Epoch 38/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8955 - loss: 0.2448 - val_accuracy: 0.9228 - val_loss: 0.2147\n",
            "Epoch 39/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.2404 - val_accuracy: 0.9074 - val_loss: 0.2205\n",
            "Epoch 40/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.2363 - val_accuracy: 0.9095 - val_loss: 0.2144\n",
            "Epoch 41/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9035 - loss: 0.2416 - val_accuracy: 0.9095 - val_loss: 0.2106\n",
            "Epoch 42/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2365 - val_accuracy: 0.9126 - val_loss: 0.2112\n",
            "Epoch 43/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.2331 - val_accuracy: 0.9146 - val_loss: 0.2039\n",
            "Epoch 44/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8954 - loss: 0.2456 - val_accuracy: 0.9218 - val_loss: 0.2046\n",
            "Epoch 45/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.2310 - val_accuracy: 0.9167 - val_loss: 0.2042\n",
            "Epoch 46/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2102 - val_accuracy: 0.9239 - val_loss: 0.1983\n",
            "Epoch 47/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8968 - loss: 0.2200 - val_accuracy: 0.9280 - val_loss: 0.1957\n",
            "Epoch 48/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9019 - loss: 0.2371 - val_accuracy: 0.9270 - val_loss: 0.1956\n",
            "Epoch 49/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9023 - loss: 0.2155 - val_accuracy: 0.9270 - val_loss: 0.1929\n",
            "Epoch 50/50\n",
            "\u001b[1m243/243\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9115 - loss: 0.2145 - val_accuracy: 0.9280 - val_loss: 0.1916\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9378 - loss: 0.1613\n",
            "Test Loss: 0.1743\n",
            "Test Accuracy: 0.9350\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Build CNN model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=16)\n",
        "\n",
        "# Evaluate model\n",
        "eval_result = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {eval_result[0]:.4f}\")\n",
        "print(f\"Test Accuracy: {eval_result[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhBOA3CN8K5P",
        "outputId": "596b0d9f-56ec-453e-ca99-447d6116b3fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.94\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94       640\n",
            "           1       0.93      0.94      0.94       576\n",
            "\n",
            "    accuracy                           0.94      1216\n",
            "   macro avg       0.94      0.94      0.94      1216\n",
            "weighted avg       0.94      0.94      0.94      1216\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# K-Nearest Neighbors Model\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBxXICS88SBf",
        "outputId": "23731d85-d9fc-4530-bcb7-e1bb72d5c5e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi Decision Tree: 0.9498\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95       640\n",
            "           1       0.95      0.94      0.95       576\n",
            "\n",
            "    accuracy                           0.95      1216\n",
            "   macro avg       0.95      0.95      0.95      1216\n",
            "weighted avg       0.95      0.95      0.95      1216\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Decision Tree\n",
        "tree_model = DecisionTreeClassifier(random_state=42)\n",
        "tree_model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred = tree_model.predict(X_test)\n",
        "\n",
        "# Evaluasi\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Akurasi Decision Tree: {accuracy:.4f}\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPKkn27j9FQy",
        "outputId": "209fe661-5863-4879-874f-3057d5b3be4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi C4.5 (Decision Tree dengan Entropy): 0.9515\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.95       640\n",
            "           1       0.94      0.95      0.95       576\n",
            "\n",
            "    accuracy                           0.95      1216\n",
            "   macro avg       0.95      0.95      0.95      1216\n",
            "weighted avg       0.95      0.95      0.95      1216\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Decision Tree pakai C4.5 (pakai entropy)\n",
        "c45_model = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "c45_model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi\n",
        "y_pred = c45_model.predict(X_test)\n",
        "\n",
        "# Evaluasi\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Akurasi C4.5 (Decision Tree dengan Entropy): {accuracy:.4f}\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lcj0bNjSAaHM",
        "outputId": "8cce6ca8-f1f8-46d7-a9a4-3176a3b671be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi Random Forest: 0.9688\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print(f\"Akurasi Random Forest: {accuracy_rf:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rGfx-30NA4ov"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "rf_predictions = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "yXkTbNPOA6qP"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "nn = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
        "nn.fit(X_train, y_train)\n",
        "\n",
        "nn_predictions = nn.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZFdNHl3BQr9",
        "outputId": "dc960b9f-04f6-4328-d1ea-df4d85aaa599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi Random Forest: 0.9688\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
        "print(f\"Akurasi Random Forest: {rf_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKGtMMBTBOgr",
        "outputId": "fde39758-fb41-4229-95bc-fae3d3b9f10e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi Neural Network: 0.9638\n"
          ]
        }
      ],
      "source": [
        "nn_accuracy = accuracy_score(y_test, nn_predictions)\n",
        "print(f\"Akurasi Neural Network: {nn_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "U6QtmudjBAnc"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Gabungkan prediksi sebagai fitur baru\n",
        "combined_predictions = np.column_stack((rf_predictions, nn_predictions))\n",
        "\n",
        "# Gunakan model lain untuk memprediksi hasil akhir\n",
        "final_model = LogisticRegression()\n",
        "final_model.fit(combined_predictions, y_test)\n",
        "\n",
        "final_predictions = final_model.predict(combined_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfKzJ0pjBKAp",
        "outputId": "0948d562-cf8c-4089-e25f-39966512e21b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi Gabungan: 0.9688\n"
          ]
        }
      ],
      "source": [
        "final_accuracy = accuracy_score(y_test, final_predictions)\n",
        "print(f\"Akurasi Gabungan: {final_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHClBd9CCgCT",
        "outputId": "f257ac7f-b6d6-49ff-87ce-2914cfe243dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
            "Best Accuracy: 0.959670781893004\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Definisikan parameter grid untuk Random Forest\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Grid Search untuk Random Forest\n",
        "grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Lihat parameter terbaik dan akurasi terbaik\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VubtjrMwChzP",
        "outputId": "8c5f2203-2966-4674-adc2-4b5a6a034f17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi XGBoost: 0.9638\n"
          ]
        }
      ],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Latih model XGBoost\n",
        "xgb_model = xgb.XGBClassifier(eval_metric='mlogloss')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi dan hitung akurasi\n",
        "xgb_predictions = xgb_model.predict(X_test)\n",
        "xgb_accuracy = accuracy_score(y_test, xgb_predictions)\n",
        "\n",
        "print(f\"Akurasi XGBoost: {xgb_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaYQ8caoCnyE",
        "outputId": "a2fbeed5-c903-4f92-c5f9-a0f4a285475a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\UMMY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi Voting Classifier: 0.9564\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Definisikan model-model yang akan digabungkan\n",
        "rf = RandomForestClassifier(n_estimators=100)\n",
        "svm = SVC(probability=True)\n",
        "nn = MLPClassifier(hidden_layer_sizes=(100,))\n",
        "\n",
        "# Gabungkan model dalam voting classifier\n",
        "voting_clf = VotingClassifier(estimators=[('rf', rf), ('svm', svm), ('nn', nn)], voting='soft')\n",
        "\n",
        "# Latih Voting Classifier\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi dan hitung akurasi\n",
        "voting_predictions = voting_clf.predict(X_test)\n",
        "voting_accuracy = accuracy_score(y_test, voting_predictions)\n",
        "\n",
        "print(f\"Akurasi Voting Classifier: {voting_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT81cx77Crf0",
        "outputId": "ef5d3219-432a-41e0-815a-2389d1559d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi dengan SMOTE: 0.9646\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Terapkan SMOTE\n",
        "smote = SMOTE()\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Latih model dengan data SMOTE\n",
        "rf.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Prediksi dan hitung akurasi\n",
        "rf_smote_predictions = rf.predict(X_test)\n",
        "rf_smote_accuracy = accuracy_score(y_test, rf_smote_predictions)\n",
        "\n",
        "print(f\"Akurasi dengan SMOTE: {rf_smote_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dRxVktICyP1",
        "outputId": "3b34c0ed-94c6-4b40-af99-791985e57610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi rata-rata dengan Cross-Validation: 0.9421\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Gunakan cross-validation pada Random Forest\n",
        "cv_scores = cross_val_score(rf, X, y, cv=5, scoring='accuracy')\n",
        "print(f\"Akurasi rata-rata dengan Cross-Validation: {cv_scores.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUtxuYkNC17A",
        "outputId": "17c94d98-e5f9-41f3-bced-8bb7730d549d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi tiap fold: [1.         1.         0.95473251 0.80823045 0.9473251 ]\n",
            "Akurasi rata-rata k-fold: 0.9421\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Misalkan X dan y adalah data fitur dan label\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Lakukan k-fold cross-validation, misal k=5\n",
        "cv_scores = cross_val_score(rf, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Cetak hasil akurasi tiap fold dan rata-ratanya\n",
        "print(f\"Akurasi tiap fold: {cv_scores}\")\n",
        "print(f\"Akurasi rata-rata k-fold: {cv_scores.mean():.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGcTlKQ3Edmm",
        "outputId": "bc7cb92b-8883-4daa-dfb9-5f7f65c916ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\UMMY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.6700 - loss: 0.6018 - val_accuracy: 0.7245 - val_loss: 0.5111\n",
            "Epoch 2/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7509 - loss: 0.4811 - val_accuracy: 0.7738 - val_loss: 0.4602\n",
            "Epoch 3/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7982 - loss: 0.4371 - val_accuracy: 0.7936 - val_loss: 0.4182\n",
            "Epoch 4/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8118 - loss: 0.4068 - val_accuracy: 0.8133 - val_loss: 0.4032\n",
            "Epoch 5/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8420 - loss: 0.3795 - val_accuracy: 0.8347 - val_loss: 0.3708\n",
            "Epoch 6/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8421 - loss: 0.3593 - val_accuracy: 0.8421 - val_loss: 0.3484\n",
            "Epoch 7/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8605 - loss: 0.3270 - val_accuracy: 0.8668 - val_loss: 0.3250\n",
            "Epoch 8/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8826 - loss: 0.2980 - val_accuracy: 0.8692 - val_loss: 0.3149\n",
            "Epoch 9/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8757 - loss: 0.2928 - val_accuracy: 0.8692 - val_loss: 0.3050\n",
            "Epoch 10/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8863 - loss: 0.2738 - val_accuracy: 0.8857 - val_loss: 0.2799\n",
            "Epoch 11/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8989 - loss: 0.2534 - val_accuracy: 0.9038 - val_loss: 0.2706\n",
            "Epoch 12/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9093 - loss: 0.2278 - val_accuracy: 0.9071 - val_loss: 0.2540\n",
            "Epoch 13/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9159 - loss: 0.2311 - val_accuracy: 0.9079 - val_loss: 0.2352\n",
            "Epoch 14/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.2040 - val_accuracy: 0.9268 - val_loss: 0.2291\n",
            "Epoch 15/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9349 - loss: 0.1906 - val_accuracy: 0.9211 - val_loss: 0.2263\n",
            "Epoch 16/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9317 - loss: 0.1952 - val_accuracy: 0.9145 - val_loss: 0.2300\n",
            "Epoch 17/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9334 - loss: 0.1829 - val_accuracy: 0.9383 - val_loss: 0.2050\n",
            "Epoch 18/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9464 - loss: 0.1673 - val_accuracy: 0.9350 - val_loss: 0.2030\n",
            "Epoch 19/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9347 - loss: 0.1676 - val_accuracy: 0.9400 - val_loss: 0.1896\n",
            "Epoch 20/20\n",
            "\u001b[1m152/152\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9429 - loss: 0.1619 - val_accuracy: 0.9416 - val_loss: 0.1807\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Akurasi CNN: 0.9416\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Misalkan X adalah fitur dan y adalah label\n",
        "# Normalisasi data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Ubah data ke bentuk 3D untuk CNN\n",
        "# (samples, features, 1) -> kita hanya menambah dimensi untuk 'channel'\n",
        "X_reshaped = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
        "\n",
        "# Membagi data menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Membuat model CNN\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, 3, activation='relu', input_shape=(X_train.shape[1], 1)))  # Layer Conv1D\n",
        "model.add(MaxPooling1D(2))  # Layer Pooling\n",
        "model.add(Flatten())  # Flatten output dari Conv1D ke bentuk vektor\n",
        "model.add(Dense(64, activation='relu'))  # Dense Layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output Layer (Binary classification)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluasi model\n",
        "y_pred = (model.predict(X_test) > 0.5).astype('int32')  # Prediksi dengan threshold 0.5\n",
        "\n",
        "# Hitung akurasi\n",
        "cnn_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Akurasi CNN: {cnn_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "fXYJFpLUXne5",
        "outputId": "2a11fee3-ee37-4da5-dd90-63391e35e571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  ca thal  target\n",
            "0   63    1   3       145   233    1        0      150      0      2.3      0   0    1       1\n",
            "1   37    1   2       130   250    0        1      187      0      3.5      0   0    2       1\n",
            "2   41    0   1       130   204    0        0      172      0      1.4      2   0    2       1\n",
            "3   56    1   1       120   236    0        1      178      0      0.8      2   0    2       1\n",
            "4   57    0   0       120   354    0        1      163      1      0.6      2   0    2       1\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'No'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-319c8d9578bc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \"\"\"\n\u001b[1;32m    929\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'No'"
          ]
        }
      ],
      "source": [
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"heart.csv\")  # Sesuaikan dengan nama file dataset\n",
        "\n",
        "pd.set_option(\"display.width\", 1000)\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "\n",
        "# Cek data awal\n",
        "print(df.head())\n",
        "\n",
        "# Pisahkan fitur (X) dan target (y)\n",
        "X = df.drop(columns=[\"target\"])  # Semua kolom kecuali target\n",
        "y = df[\"target\"]  # Target: 0 (tidak sakit), 1 (sakit)\n",
        "\n",
        "# Split data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVpqaKP7XtAp",
        "outputId": "098af223-aa4d-42e4-b1d2-82218d8b8888"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7138\n",
            "Log Loss: 0.5787\n",
            "F1-Score: 0.7136\n",
            "Precision: 0.7140\n",
            "Recall: 0.7138\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, log_loss, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Inisialisasi k-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# List untuk menampung hasil tiap fold\n",
        "accuracies = []\n",
        "log_losses = []\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "# Looping k-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Inisialisasi model Naive Bayes untuk data numerik\n",
        "    model = GaussianNB()\n",
        "\n",
        "    # Latih model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Prediksi\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "    # Evaluasi\n",
        "    accuracies.append(accuracy_score(y_test, y_pred))\n",
        "    log_losses.append(log_loss(y_test, y_pred_proba))\n",
        "    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
        "    precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
        "    recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "# Tampilkan hasil rata-rata\n",
        "print(f\"Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Log Loss: {np.mean(log_losses):.4f}\")\n",
        "print(f\"F1-Score: {np.mean(f1_scores):.4f}\")\n",
        "print(f\"Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Recall: {np.mean(recalls):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oM5lAD-jXYu",
        "outputId": "c7d44e4f-0aab-4af8-b3f8-19ff1387f89f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naïve Bayes Accuracy: 0.71499176276771\n",
            "SVM Accuracy: 0.729818780889621\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\UMMY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5272 - loss: 3.8581\n",
            "Epoch 2/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5270 - loss: 1.0563\n",
            "Epoch 3/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5370 - loss: 0.7890\n",
            "Epoch 4/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5526 - loss: 0.7247\n",
            "Epoch 5/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5645 - loss: 0.7142\n",
            "Epoch 6/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5871 - loss: 0.6815\n",
            "Epoch 7/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5926 - loss: 0.6734\n",
            "Epoch 8/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5957 - loss: 0.6661\n",
            "Epoch 9/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6011 - loss: 0.6466\n",
            "Epoch 10/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6310 - loss: 0.6216\n",
            "Epoch 11/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6399 - loss: 0.6189\n",
            "Epoch 12/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6496 - loss: 0.6036\n",
            "Epoch 13/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6527 - loss: 0.5944\n",
            "Epoch 14/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6661 - loss: 0.5820\n",
            "Epoch 15/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6855 - loss: 0.5676\n",
            "Epoch 16/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6963 - loss: 0.5511\n",
            "Epoch 17/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6937 - loss: 0.5532\n",
            "Epoch 18/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6928 - loss: 0.5526\n",
            "Epoch 19/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6878 - loss: 0.5522\n",
            "Epoch 20/20\n",
            "\u001b[1m342/342\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7064 - loss: 0.5338\n",
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7508 - loss: 0.4708\n",
            "CNN Accuracy: 0.7248764634132385\n",
            "KNN Accuracy: 0.8945634266886326\n",
            "Decision Tree Accuracy: 0.9522240527182867\n",
            "C4.5 Accuracy: 0.9555189456342669\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Load dataset (gantilah dengan dataset yang sesuai)\n",
        "#data = pd.read_csv(\"heart.csv\")\n",
        "'''\n",
        "# Pisahkan fitur dan label\n",
        "X = data.drop(columns=['target'])  # Target adalah kolom yang diprediksi\n",
        "y = data['target']\n",
        "\n",
        "# Split data menjadi training dan testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalisasi fitur\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "'''\n",
        "# 1. Naïve Bayes\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "nb_pred = nb_model.predict(X_test)\n",
        "print(\"Naïve Bayes Accuracy:\", accuracy_score(y_test, nb_pred))\n",
        "\n",
        "# 2. Support Vector Machine (SVM)\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train, y_train)\n",
        "svm_pred = svm_model.predict(X_test)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
        "\n",
        "# 3. Convolutional Neural Network (CNN) - Simpel\n",
        "cnn_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(X_train, y_train, epochs=20, batch_size=16, verbose=1)\n",
        "cnn_loss, cnn_acc = cnn_model.evaluate(X_test, y_test)\n",
        "print(\"CNN Accuracy:\", cnn_acc)\n",
        "\n",
        "# 4. K-Nearest Neighbors (KNN)\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train, y_train)\n",
        "knn_pred = knn_model.predict(X_test)\n",
        "print(\"KNN Accuracy:\", accuracy_score(y_test, knn_pred))\n",
        "\n",
        "# 5. Decision Tree\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, dt_pred))\n",
        "\n",
        "# 6. C4.5 (Menggunakan DecisionTreeClassifier dengan entropy sebagai criterion)\n",
        "c45_model = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "c45_model.fit(X_train, y_train)\n",
        "c45_pred = c45_model.predict(X_test)\n",
        "print(\"C4.5 Accuracy:\", accuracy_score(y_test, c45_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQi_IffJiYmv",
        "outputId": "8db75097-e286-47c6-d7dd-f18772b89c4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7138\n",
            "Log Loss: 0.5787\n",
            "F1-Score: 0.7136\n",
            "Precision: 0.7140\n",
            "Recall: 0.7138\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, log_loss, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Initialize k-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store metrics for each fold\n",
        "accuracies = []\n",
        "log_losses = []\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "# Initialize classifier\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split data into train and test sets for this fold\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Train the classifier\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = clf.predict(X_test)\n",
        "    y_pred_proba = clf.predict_proba(X_test)  # Probabilities for log loss\n",
        "\n",
        "    # Calculate accuracy\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    # Calculate log loss\n",
        "    loss = log_loss(y_test, y_pred_proba)\n",
        "    log_losses.append(loss)\n",
        "\n",
        "    # Calculate F1-score, precision, and recall\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    f1_scores.append(f1)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "\n",
        "# Print average metrics across all folds\n",
        "print(f\"Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Log Loss: {np.mean(log_losses):.4f}\")\n",
        "print(f\"F1-Score: {np.mean(f1_scores):.4f}\")\n",
        "print(f\"Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Recall: {np.mean(recalls):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "iCjIbZ0fj-Id"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7031\n",
            "Log Loss: 0.6019\n",
            "F1-Score: 0.7028\n",
            "Precision: 0.7028\n",
            "Recall: 0.7031\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, log_loss, f1_score, precision_score, recall_score\n",
        "\n",
        "# Split data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize classifier\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "y_pred_proba = clf.predict_proba(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "logloss = log_loss(y_test, y_pred_proba)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Log Loss: {logloss:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "VzA8Er9zkiv9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'var_smoothing': 1e-06}\n",
            "Best Accuracy: 0.7146090534979425\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Model\n",
        "nb = GaussianNB()\n",
        "\n",
        "# Daftar parameter yang diuji\n",
        "param_grid = {\n",
        "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
        "}\n",
        "\n",
        "# Grid Search\n",
        "grid_search = GridSearchCV(nb, param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print hasil terbaik\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ7vOhCvWj9I",
        "outputId": "03ae8b30-c30f-4e5b-d703-63dd04591337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7138\n",
            "Log Loss: 0.5787\n",
            "F1-Score: 0.7136\n",
            "Precision: 0.7140\n",
            "Recall: 0.7138\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, log_loss, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Inisialisasi k-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# List untuk menampung hasil tiap fold\n",
        "accuracies = []\n",
        "log_losses = []\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "# Looping k-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Inisialisasi model Naive Bayes untuk data numerik\n",
        "    model = GaussianNB()\n",
        "\n",
        "    # Latih model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Prediksi\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "    # Evaluasi\n",
        "    accuracies.append(accuracy_score(y_test, y_pred))\n",
        "    log_losses.append(log_loss(y_test, y_pred_proba))\n",
        "    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
        "    precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
        "    recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "# Tampilkan hasil rata-rata\n",
        "print(f\"Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Log Loss: {np.mean(log_losses):.4f}\")\n",
        "print(f\"F1-Score: {np.mean(f1_scores):.4f}\")\n",
        "print(f\"Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Recall: {np.mean(recalls):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "hhyXG2hGiwu-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.7031\n",
            "Log Loss: 0.6019\n",
            "F1-Score: 0.7028\n",
            "Precision: 0.7028\n",
            "Recall: 0.7031\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, log_loss, f1_score, precision_score, recall_score\n",
        "\n",
        "# Split data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize classifier\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Train the classifier\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "y_pred_proba = clf.predict_proba(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "logloss = log_loss(y_test, y_pred_proba)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Log Loss: {logloss:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyRbFx95fopO"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, log_loss, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "'''\n",
        "# Load dataset\n",
        "#df = pd.read_csv(\"heart.csv\")\n",
        "\n",
        "# Pisahkan fitur (X) dan target (y)\n",
        "X = df.drop(columns=[\"target\"])\n",
        "y = df[\"target\"]\n",
        "\n",
        "# Standarisasi data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "'''\n",
        "# Gunakan StratifiedKFold agar tiap fold tetap proporsional\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Simpan metrik evaluasi\n",
        "accuracies = []\n",
        "log_losses = []\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "# Model Naïve Bayes\n",
        "clf = GaussianNB()\n",
        "\n",
        "# K-Fold cross-validation\n",
        "for train_index, test_index in skf.split(X_scaled, y):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]  # Pastikan pakai `.iloc` untuk Pandas\n",
        "\n",
        "    # Train model\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Prediksi\n",
        "    y_pred = clf.predict(X_test)\n",
        "    y_pred_proba = clf.predict_proba(X_test)\n",
        "\n",
        "    # Evaluasi\n",
        "    accuracies.append(accuracy_score(y_test, y_pred))\n",
        "    log_losses.append(log_loss(y_test, y_pred_proba, labels=np.unique(y)))  # Perbaikan di sini\n",
        "    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
        "    precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
        "    recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "# Cetak hasil rata-rata\n",
        "print(f\"Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Log Loss: {np.mean(log_losses):.4f}\")\n",
        "print(f\"F1-Score: {np.mean(f1_scores):.4f}\")\n",
        "print(f\"Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Recall: {np.mean(recalls):.4f}\")\n",
        "\n",
        "# Simpan model Naïve Bayes\n",
        "with open('naive_bayes_model.pkl', 'wb') as model_file:\n",
        "    pickle.dump(clf, model_file)\n",
        "\n",
        "# Simpan scaler\n",
        "with open('scaler.pkl', 'wb') as scaler_file:\n",
        "    pickle.dump(scaler, scaler_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1ek3WViZKaX",
        "outputId": "f5f9caa4-9d49-4d9e-df50-cb254288d4d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Akurasi Model: 0.97\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       640\n",
            "           1       0.97      0.97      0.97       576\n",
            "\n",
            "    accuracy                           0.97      1216\n",
            "   macro avg       0.97      0.97      0.97      1216\n",
            "weighted avg       0.97      0.97      0.97      1216\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Buat model Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Training model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Prediksi pada data test\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluasi akurasi\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Akurasi Model: {accuracy:.2f}\")\n",
        "\n",
        "# Laporan klasifikasi\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[621  19]\n",
            " [ 19 557]]\n",
            "TP: 557, TN: 621, FP: 19, FN: 19\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Setelah prediksi ya, contoh:\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Bikin Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "\n",
        "TP = cm[1, 1]  # True Positive (Prediksi 1, sebenarnya 1)\n",
        "TN = cm[0, 0]  # True Negative (Prediksi 0, sebenarnya 0)\n",
        "FP = cm[0, 1]  # False Positive (Prediksi 1, sebenarnya 0)\n",
        "FN = cm[1, 0]  # False Negative (Prediksi 0, sebenarnya 1)\n",
        "\n",
        "print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYSOdWHJJRCB",
        "outputId": "bc927a26-bd78-43fb-fe66-a7e35786c92d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hasil Prediksi: Tidak Berisiko Penyakit Jantung\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\UMMY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\UMMY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Biar aman, ulang fit scaler pakai data training dulu\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Input data baru\n",
        "import numpy as np\n",
        "\n",
        "data_baru = np.array([[63, 1, 0, 145, 233, 1, 2, 150, 0, 2.3, 2, 0, 1]])\n",
        "\n",
        "# Normalisasi\n",
        "data_baru = scaler.transform(data_baru)\n",
        "\n",
        "# Prediksi hasil\n",
        "prediksi = model.predict(data_baru)\n",
        "\n",
        "if prediksi[0] == 1:\n",
        "    print(\"Hasil Prediksi: Berisiko Penyakit Jantung\")\n",
        "else:\n",
        "    print(\"Hasil Prediksi: Tidak Berisiko Penyakit Jantung\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRfg1nkLJDaW",
        "outputId": "4fe5bd09-cb63-4deb-fc4d-080707090f5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hasil Prediksi: Tidak Berisiko Penyakit Jantung\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\UMMY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\UMMY\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Input data baru (sesuai urutan fitur training)\n",
        "import numpy as np\n",
        "\n",
        "data_baru = np.array([[63, 1, 0, 145, 233, 1, 2, 150, 0, 2.3, 2, 0, 1]])  # contoh input\n",
        "\n",
        "# Jangan lupa normalisasi pakai scaler yang sama\n",
        "data_baru = scaler.transform(data_baru)\n",
        "\n",
        "# Prediksi hasil\n",
        "prediksi = model.predict(data_baru)\n",
        "\n",
        "if prediksi[0] == 1:\n",
        "    print(\"Hasil Prediksi: Berisiko Penyakit Jantung\")\n",
        "else:\n",
        "    print(\"Hasil Prediksi: Tidak Berisiko Penyakit Jantung\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9623\n",
            "Log Loss: 0.0936\n",
            "F1-Score: 0.9623\n",
            "Precision: 0.9624\n",
            "Recall: 0.9623\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, log_loss, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Inisialisasi k-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# List untuk menampung hasil tiap fold\n",
        "accuracies = []\n",
        "log_losses = []\n",
        "f1_scores = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "\n",
        "# Looping k-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Inisialisasi model Random Forest\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    # Latih model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Prediksi\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "    # Evaluasi\n",
        "    accuracies.append(accuracy_score(y_test, y_pred))\n",
        "    log_losses.append(log_loss(y_test, y_pred_proba))\n",
        "    f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
        "    precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
        "    recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "# Tampilkan hasil rata-rata\n",
        "print(f\"Accuracy: {np.mean(accuracies):.4f}\")\n",
        "print(f\"Log Loss: {np.mean(log_losses):.4f}\")\n",
        "print(f\"F1-Score: {np.mean(f1_scores):.4f}\")\n",
        "print(f\"Precision: {np.mean(precisions):.4f}\")\n",
        "print(f\"Recall: {np.mean(recalls):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "34ZadkAHrHqb",
        "outputId": "6fe9f5a0-29d7-444c-91c0-6afce53e85d1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7ba08172991a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Setelah prediksi ya, contoh:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Bikin Confusion Matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Setelah prediksi ya, contoh:\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Bikin Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Biar lebih jelas\n",
        "TP = cm[1, 1]  # True Positive (Prediksi 1, sebenarnya 1)\n",
        "TN = cm[0, 0]  # True Negative (Prediksi 0, sebenarnya 0)\n",
        "FP = cm[0, 1]  # False Positive (Prediksi 1, sebenarnya 0)\n",
        "FN = cm[1, 0]  # False Negative (Prediksi 0, sebenarnya 1)\n",
        "\n",
        "print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79F5s1v1IoVr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dapatkan importance tiap fitur\n",
        "importances = model.feature_importances_\n",
        "\n",
        "# Buat plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(X_train.columns, importances)\n",
        "plt.xlabel('Fitur')\n",
        "plt.ylabel('Importance')\n",
        "plt.title('Feature Importance - Random Forest')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
